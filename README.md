# Voice Based Medical Assistant 

A voice-enabled, AI-powered medical assistant that listens to your health concerns, analyzes images of affected areas, and provides preliminary advice and information.

![Project Demo](https://github.com/komal-sharma19/Voice-Based-Medical-Assistant/blob/main/Screenshot%202025-08-29%20210329.png)


## üìù Overview

This project is a sophisticated medical chatbot designed to simulate an initial consultation with a doctor. It leverages the power of Large Language Models (LLMs) to understand user queries, analyze symptoms from both voice and images, and provide a conversational, spoken response. The user interface is built with Gradio, making it easy to interact with the system.

## ‚ú® Features

- **Voice Interaction**: Speak your symptoms naturally. The app records your voice, converts it to text, and processes it.
- **Image Analysis**: Upload an image of a physical condition (e.g., a skin rash) for visual analysis.
- **AI-Powered Diagnosis**: Utilizes Google's Gemini Pro and Gemini Pro Vision models to understand the context, analyze symptoms, and generate a coherent, medically-informed response.
- **Text-to-Speech Output**: The AI's response is converted back into natural-sounding speech and played automatically.
- **User-Friendly Interface**: A simple and intuitive web interface powered by Gradio for easy interaction.

## ‚öôÔ∏è How It Works

The application follows a seamless flow from user input to AI-generated response:

1.  **Input**: The user records their health issue using the microphone and can optionally upload an image.
2.  **Voice-to-Text**: The recorded audio is processed by the `voice_of_the_patient` module, which transcribes the speech into text.
3.  **AI Processing**: The transcribed text and the uploaded image are sent to the `brain_of_the_doctor` module.
    - If an image is provided, the Gemini Pro Vision model analyzes it along with the text prompt.
    - If only text is provided, the Gemini Pro model processes the query.
    - A carefully crafted prompt instructs the model to act as a compassionate and knowledgeable doctor.
4.  **Text-to-Speech**: The text response generated by the AI is passed to the `voice_of_the_doctor` module, which uses Google Text-to-Speech (gTTS) to convert the text into an audio file.
5.  **Output**: The Gradio interface displays the conversation history and automatically plays the generated audio response for the user.

## üõ†Ô∏è Technology Stack

- **Backend**: Python
- **AI/ML**: Google Generative AI (Gemini Pro, Gemini Pro Vision)
- **Web Framework**: Gradio
- **Speech-to-Text**: `speech_recognition`
- **Text-to-Speech**: `gTTS`
- **Audio Processing**: `pydub`
- **Image Processing**: `Pillow`
- **Environment Variables**: `python-dotenv`

## üöÄ Setup and Installation

Follow these steps to get the project running on your local machine.

### 1. Prerequisites

- Python 3.8+
- **FFmpeg**: This is required by the `pydub` library for audio processing. Download it from [ffmpeg.org](https://ffmpeg.org/download.html) and ensure it's installed and accessible in your system's PATH.

### 2. Clone the Repository

```bash
git clone https://github.com/komal-sharma19/AIMedicalChatbot.git
cd AIMedicalChatbot
```

### 3. Set up a virtual Environment
It's highly recommended to use a virtual environment to manage dependencies and avoid conflicts.

For Windows:
```bash
python -m venv venv
venv\Scripts\activate
```

For macOS/Linux:
```bash
python3 -m venv venv
source venv/bin/activate
```

### 4. Install Dependencies
Install all the required Python packages using the **requirements.txt** file.

```bash
pip install -r requirements.txt
```

### 5. Configure Environment Variables
The application requires an API key from Google AI Studio to function.

1. Create a file named .env in the root of the project directory.
2. Get your API key from Google AI Studio.
3. Add your API key to the .env file like this:
   ```bash
   GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
   ```

### ‚ñ∂Ô∏è Usage
Once the setup is complete, run the  Shell and Gradio application with the following command:
```bash
pipenv Shell
python gradio.py
```

This will start a local web server. Open the URL provided in the terminal (usually http://127.0.0.1:7860) in your web browser to interact with the AI Medical Chatbot.

### üìÇ File Structure
.
‚îú‚îÄ‚îÄ .env                  # Stores environment variables (must be created manually)

‚îú‚îÄ‚îÄ gradio_app.py         # Main file to run the Gradio web interface

‚îú‚îÄ‚îÄ brain_of_the_doctor.py  # Handles interaction with the Google Gemini AI models

‚îú‚îÄ‚îÄ voice_of_the_patient.py # Manages Speech-to-Text conversion

‚îú‚îÄ‚îÄ voice_of_the_doctor.py  # Manages Text-to-Speech conversion

‚îú‚îÄ‚îÄ requirements.txt      # Lists all Python dependencies for the project

‚îú‚îÄ‚îÄ voice_based Medical Assistant.jpg # Demo image for the README

‚îî‚îÄ‚îÄ ...                   # Other testing images and audio files



### üîÆ Future Improvements
**1. Conversation History:** Implement a system to remember past interactions within a session for better contextual understanding.

**2. Multi-language Support:** Extend the chatbot to understand and respond in multiple languages.

**3. Deployment:** Deploy the application to a cloud service like Hugging Face Spaces, GCP, or AWS for public access.

**4. Enhanced TTS:** Integrate with more advanced, emotionally expressive TTS services for a more natural-sounding voice.

**5. Disclaimer:** Add a more prominent and clear disclaimer about the bot not being a substitute for a real medical professional.
