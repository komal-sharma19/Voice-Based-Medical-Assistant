# Voice Based Medical Assistant 

A voice-enabled, AI-powered medical assistant that listens to your health concerns, analyzes images of affected areas, and provides preliminary advice and information.

![Project Demo](https://github.com/komal-sharma19/Voice-Based-Medical-Assistant/blob/main/Screenshot%202025-08-29%20210329.png)


## üìù Overview

This project is a sophisticated medical chatbot designed to simulate an initial consultation with a doctor. It leverages the power of Large Language Models (LLMs) to understand user queries, analyze symptoms from both voice and images, and provide a conversational, spoken response. The user interface is built with Gradio, making it easy to interact with the system.

## ‚ú® Features

- **Voice Interaction**: Speak your symptoms naturally. The app records your voice, converts it to text, and processes it.
- **Image Analysis**: Upload an image of a physical condition (e.g., a skin rash) for visual analysis.
- **AI-Powered Diagnosis**: Utilizes Google's Gemini Pro and Gemini Pro Vision models to understand the context, analyze symptoms, and generate a coherent, medically-informed response.
- **Text-to-Speech Output**: The AI's response is converted back into natural-sounding speech and played automatically.
- **User-Friendly Interface**: A simple and intuitive web interface powered by Gradio for easy interaction.

## ‚öôÔ∏è How It Works

The application follows a seamless flow from user input to AI-generated response:

1.  **Input**: The user records their health issue using the microphone and can optionally upload an image.
2.  **Voice-to-Text**: The recorded audio is processed by the `voice_of_the_patient` module, which transcribes the speech into text.
3.  **AI Processing**: The transcribed text and the uploaded image are sent to the `brain_of_the_doctor` module.
    - If an image is provided, the Gemini Pro Vision model analyzes it along with the text prompt.
    - If only text is provided, the Gemini Pro model processes the query.
    - A carefully crafted prompt instructs the model to act as a compassionate and knowledgeable doctor.
4.  **Text-to-Speech**: The text response generated by the AI is passed to the `voice_of_the_doctor` module, which uses Google Text-to-Speech (gTTS) to convert the text into an audio file.
5.  **Output**: The Gradio interface displays the conversation history and automatically plays the generated audio response for the user.

## üõ†Ô∏è Technology Stack

- **Backend**: Python
- **AI/ML**: Google Generative AI (Gemini Pro, Gemini Pro Vision)
- **Web Framework**: Gradio
- **Speech-to-Text**: `speech_recognition`
- **Text-to-Speech**: `gTTS`
- **Audio Processing**: `pydub`
- **Image Processing**: `Pillow`
- **Environment Variables**: `python-dotenv`

## üöÄ Setup and Installation

Follow these steps to get the project running on your local machine.

### 1. Prerequisites

- Python 3.8+
- **FFmpeg**: This is required by the `pydub` library for audio processing. Download it from [ffmpeg.org](https://ffmpeg.org/download.html) and ensure it's installed and accessible in your system's PATH.

### 2. Clone the Repository

```bash
git clone https://github.com/komal-sharma19/AIMedicalChatbot.git
cd AIMedicalChatbot

### 3. Set up a virtual Environment

